{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baby Cry Analysis & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Let's train a machine learning algorithm and test it's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by collecting all of the sample audio files we have, chopping them into smaller audio snippets and training a collection of machine learning algorithms with part of this data.  With another part of the data we will test and see how well the algorithms predict data they have never seen before and then choose the best algorithm for our project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1:  Grab the audio file and its label (we have 3 labels: hungry, pain, and asphyxia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store all audio files in dictionary where key: filename, value: label\n",
    "import os\n",
    "raw_audio = dict()\n",
    "\n",
    "\n",
    "directory = 'Full_hunger'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'hungry'\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "directory = 'Full_pain'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'pain'\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "directory = 'Full_asphyxia'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'asphyxia'\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "#print raw_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#If you are having issues with python being able to make the different directories, try doing it manually or with the os.system commands\n",
    "\n",
    "```os.system(\"sudo mkdir /audio\")```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Chop the audio file into 1 sec. snippets and save them in corresponding folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import wave \n",
    "import math\n",
    "\n",
    "def chop_song(filename, folder):\n",
    "    handle = wave.open(filename, 'rb')\n",
    "    frame_rate = handle.getframerate()\n",
    "    n_frames = handle.getnframes()\n",
    "    window_size = 2 * frame_rate\n",
    "    num_secs = int(math.ceil(n_frames/frame_rate))\n",
    "    #print filename\n",
    "    last_number_frames = 0\n",
    "    #Slicing Audio file\n",
    "    for i in xrange(num_secs):\n",
    "        \n",
    "        shortfilename = filename.split(\"/\")[1].split(\".\")[0]\n",
    "        snippetfilename = 'audio/' + folder + '/' + shortfilename + 'snippet' + str(i+1) + '.wav'\n",
    "        #print snippetfilename\n",
    "        snippet = wave.open(snippetfilename ,'wb')\n",
    "        snippet.setnchannels(2)\n",
    "        snippet.setsampwidth(handle.getsampwidth())\n",
    "        snippet.setframerate(frame_rate)\n",
    "        #snippet.setsampwidth(2)\n",
    "        #snippet.setframerate(11025)\n",
    "        snippet.setnframes(handle.getnframes())\n",
    "        snippet.writeframes(handle.readframes(window_size))\n",
    "        handle.setpos(handle.tell() - 1 * frame_rate)\n",
    "        #print snippetfilename, \":\", snippet.getnchannels(), snippet.getframerate(), snippet.getnframes(), snippet.getsampwidth()\n",
    "        \n",
    "        #The last audio slice might be less than a second, if this is the case, we don't want to include it because it will not fit into our matrix \n",
    "        if last_number_frames < 1:\n",
    "            last_number_frames = snippet.getnframes()\n",
    "        elif snippet.getnframes() != last_number_frames:\n",
    "            #print \"this file doesnt have the same frame size!, remaming file\"\n",
    "            os.rename(snippetfilename, snippetfilename+\".bak\")\n",
    "        snippet.close()\n",
    "\n",
    "    #handle.close()\n",
    "\n",
    "for audio_file in raw_audio:\n",
    "    chop_song(audio_file, raw_audio[audio_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Transform .wav files to frequency spectrum \"fingerprints\" using MFCC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa \n",
    "import numpy as np\n",
    "'''Chop and Transform each track'''\n",
    "X = pd.DataFrame(columns = np.arange(45), dtype = 'float32').astype(np.float32)\n",
    "j = 0\n",
    "k = 0\n",
    "for i, filename in enumerate(os.listdir('audio/pain/')):\n",
    "    last_number_frames = -1\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"audio/pain/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'pain'\n",
    "        X.loc[i] = x.loc[0]\n",
    "        j = i \n",
    "        \n",
    "\n",
    "for i, filename in enumerate(os.listdir('audio/hungry/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"audio/hungry/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'hungry'\n",
    "        X.loc[i+j] = x.loc[0] \n",
    "        k = i \n",
    "        \n",
    "for i, filename in enumerate(os.listdir('audio/asphyxia/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"audio/asphyxia/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'asphyxia'\n",
    "        X.loc[i+j+k] = x.loc[0]\n",
    "        \n",
    "#Do something with missing values. you might want to do something more sophisticated with missing values later\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.164639</td>\n",
       "      <td>47.077801</td>\n",
       "      <td>-31.072571</td>\n",
       "      <td>-96.637245</td>\n",
       "      <td>-130.160461</td>\n",
       "      <td>-123.079628</td>\n",
       "      <td>-122.755928</td>\n",
       "      <td>-106.404770</td>\n",
       "      <td>-89.965424</td>\n",
       "      <td>-90.127457</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.442520</td>\n",
       "      <td>76.313026</td>\n",
       "      <td>-2.145989</td>\n",
       "      <td>-30.406242</td>\n",
       "      <td>-61.038811</td>\n",
       "      <td>-67.060280</td>\n",
       "      <td>-54.365772</td>\n",
       "      <td>-55.774155</td>\n",
       "      <td>-47.985542</td>\n",
       "      <td>-15.517380</td>\n",
       "      <td>...</td>\n",
       "      <td>-86.546463</td>\n",
       "      <td>-30.136751</td>\n",
       "      <td>-7.350064</td>\n",
       "      <td>-10.286840</td>\n",
       "      <td>-12.592611</td>\n",
       "      <td>-13.583686</td>\n",
       "      <td>-21.501377</td>\n",
       "      <td>-11.565689</td>\n",
       "      <td>62.324951</td>\n",
       "      <td>69.309616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-29.781023</td>\n",
       "      <td>-60.232071</td>\n",
       "      <td>-96.828278</td>\n",
       "      <td>-90.998222</td>\n",
       "      <td>-94.779671</td>\n",
       "      <td>-105.075417</td>\n",
       "      <td>-97.519058</td>\n",
       "      <td>-99.080528</td>\n",
       "      <td>-105.163040</td>\n",
       "      <td>-106.028229</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.644783</td>\n",
       "      <td>-83.937691</td>\n",
       "      <td>-80.022545</td>\n",
       "      <td>-91.994202</td>\n",
       "      <td>-102.968040</td>\n",
       "      <td>-90.376099</td>\n",
       "      <td>-89.551079</td>\n",
       "      <td>-84.076927</td>\n",
       "      <td>-11.199362</td>\n",
       "      <td>3.811244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-48.579533</td>\n",
       "      <td>-68.671791</td>\n",
       "      <td>-113.557213</td>\n",
       "      <td>-111.534363</td>\n",
       "      <td>-108.681320</td>\n",
       "      <td>-106.165474</td>\n",
       "      <td>-101.677551</td>\n",
       "      <td>-95.523392</td>\n",
       "      <td>-102.661011</td>\n",
       "      <td>-105.140739</td>\n",
       "      <td>...</td>\n",
       "      <td>-80.398064</td>\n",
       "      <td>-92.367661</td>\n",
       "      <td>-95.758377</td>\n",
       "      <td>-104.873161</td>\n",
       "      <td>-106.258102</td>\n",
       "      <td>-109.926643</td>\n",
       "      <td>-111.612045</td>\n",
       "      <td>-98.675140</td>\n",
       "      <td>-91.144066</td>\n",
       "      <td>-95.634537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.824058</td>\n",
       "      <td>13.150772</td>\n",
       "      <td>-6.948591</td>\n",
       "      <td>-17.075489</td>\n",
       "      <td>-12.422709</td>\n",
       "      <td>-0.860229</td>\n",
       "      <td>3.998694</td>\n",
       "      <td>3.655787</td>\n",
       "      <td>-2.229299</td>\n",
       "      <td>-17.267118</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.970703</td>\n",
       "      <td>-41.767918</td>\n",
       "      <td>-99.628151</td>\n",
       "      <td>-110.191643</td>\n",
       "      <td>-78.499588</td>\n",
       "      <td>-62.011497</td>\n",
       "      <td>-63.363140</td>\n",
       "      <td>-67.923515</td>\n",
       "      <td>-67.200996</td>\n",
       "      <td>-55.079521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1           2           3           4           5   \\\n",
       "1  61.164639  47.077801  -31.072571  -96.637245 -130.160461 -123.079628   \n",
       "2  88.442520  76.313026   -2.145989  -30.406242  -61.038811  -67.060280   \n",
       "3 -29.781023 -60.232071  -96.828278  -90.998222  -94.779671 -105.075417   \n",
       "4 -48.579533 -68.671791 -113.557213 -111.534363 -108.681320 -106.165474   \n",
       "5  10.824058  13.150772   -6.948591  -17.075489  -12.422709   -0.860229   \n",
       "\n",
       "           6           7           8           9     ...             34  \\\n",
       "1 -122.755928 -106.404770  -89.965424  -90.127457    ...       0.000000   \n",
       "2  -54.365772  -55.774155  -47.985542  -15.517380    ...     -86.546463   \n",
       "3  -97.519058  -99.080528 -105.163040 -106.028229    ...     -90.644783   \n",
       "4 -101.677551  -95.523392 -102.661011 -105.140739    ...     -80.398064   \n",
       "5    3.998694    3.655787   -2.229299  -17.267118    ...      -9.970703   \n",
       "\n",
       "          35         36          37          38          39          40  \\\n",
       "1   0.000000   0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "2 -30.136751  -7.350064  -10.286840  -12.592611  -13.583686  -21.501377   \n",
       "3 -83.937691 -80.022545  -91.994202 -102.968040  -90.376099  -89.551079   \n",
       "4 -92.367661 -95.758377 -104.873161 -106.258102 -109.926643 -111.612045   \n",
       "5 -41.767918 -99.628151 -110.191643  -78.499588  -62.011497  -63.363140   \n",
       "\n",
       "          41         42         43  \n",
       "1   0.000000   0.000000   0.000000  \n",
       "2 -11.565689  62.324951  69.309616  \n",
       "3 -84.076927 -11.199362   3.811244  \n",
       "4 -98.675140 -91.144066 -95.634537  \n",
       "5 -67.923515 -67.200996 -55.079521  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Make a Test-Train-Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "y = X[44]\n",
    "del X[44]\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Fit the training data to a model & Check the models performance against the test data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show_err=false; \n",
       "function code_toggle_err() {\n",
       " if (code_show_err){\n",
       " $('div.output_stderr').hide();\n",
       " } else {\n",
       " $('div.output_stderr').show();\n",
       " }\n",
       " code_show_err = !code_show_err\n",
       "} \n",
       "$( document ).ready(code_toggle_err);\n",
       "</script>\n",
       "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to hide deprication warnings\n",
    "\n",
    "from IPython.display import HTML\n",
    "HTML('''<script>\n",
    "code_show_err=false; \n",
    "function code_toggle_err() {\n",
    " if (code_show_err){\n",
    " $('div.output_stderr').hide();\n",
    " } else {\n",
    " $('div.output_stderr').show();\n",
    " }\n",
    " code_show_err = !code_show_err\n",
    "} \n",
    "$( document ).ready(code_toggle_err);\n",
    "</script>\n",
    "To toggle on/off output_stderr, click <a href=\"javascript:code_toggle_err()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model, Accuracy, Precision, Recall\n",
      "    Random Forest: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.80693069306930698, 0.80875431729219438, 0.80693069306930698)\n",
      "    Logistic Regression: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.70792079207920788, 0.72826645954770641, 0.70792079207920788)\n",
      "    Decision Tree: (0.7722772277227723, 0.77233616218764733, 0.7722772277227723)\n",
      "    SVM: (0.41584158415841582, 0.17292422311538083, 0.41584158415841582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
    "        model = classifier(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        return model.score(X_test, y_test), \\\n",
    "               precision_score(y_test, y_predict), \\\n",
    "               recall_score(y_test, y_predict)\n",
    "\n",
    "print \"    Model, Accuracy, Precision, Recall\"\n",
    "print \"    Random Forest:\", get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test, n_estimators=25, max_features=5)\n",
    "print \"    Logistic Regression:\", get_scores(LogisticRegression, X_train, X_test, y_train, y_test)\n",
    "print \"    Decision Tree:\", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test)\n",
    "print \"    SVM:\", get_scores(SVC, X_train, X_test, y_train, y_test)\n",
    "#print \"    Naive Bayes:\", get_scores(MultinomialNB, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Model: (Accuracy, Precision, Recall)\n",
    "We tested four popular machine learning algorithms to see which ones had the most accuracte predictions with our test data, here are the results:\n",
    "#### Random Forest: ~80% Accuracy\n",
    "#### Logistic Regression: ~70% Accuracy\n",
    "#### Decision Tree: ~77% Accuracy\n",
    "#### Support Vector Machines: ~47% Accuracy\n",
    "\n",
    "I am glossing over a lot of details here.  Different algorithms have different performance speeds and settings that we can tweak to improve their accuracy, precision, and recall.  Random Forests usually perform best with little tweaking although they aren't the fastest in most cases. For this experiment however, I think random forests are fine for building the basic version of our application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you are satisfied with the results of your model, you can save the model into a .pkl file that you can quickly use to make predictions of new data.  I will fit a new random forest model that uses all of the data I have and save it as 'myRandomForest.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle\n",
    "\n",
    "def pickle_model(model, modelname):\n",
    "    with open('models/' + str(modelname) + '.pkl', 'wb') as f:\n",
    "        return cPickle.dump(model, f)\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X,y)\n",
    "pickle_model(model, \"myRandomForest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you pkl a model you can open it up later on as so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getModel(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "## Let's see if it works! Making Actual Predictions on new sounds\n",
    "I downloaded from YouTube an audio file of a hungry baby crying. (https://www.youtube.com/watch?v=n87mdkR4kIY) I know our dataset probably isn't big enough to make a strong prediction but let's see if we can get an algorithm working that makes a prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the model from disk into Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = getModel(\"models/myRandomForest.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Chop the wav file and store it in a folder \n",
    "I should have done a better job making the old chop_songs method more reusable, oh well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def chop_new_audio(filename, folder):\n",
    "    handle = wave.open(filename, 'rb')\n",
    "    frame_rate = handle.getframerate()\n",
    "    n_frames = handle.getnframes()\n",
    "    window_size = 1 * frame_rate\n",
    "    num_secs = int(math.ceil(n_frames/frame_rate))\n",
    "    #print filename\n",
    "    last_number_frames = 0\n",
    "    #Slicing Audio file\n",
    "    for i in xrange(num_secs):\n",
    "        \n",
    "        shortfilename = filename.split(\".\")[0]\n",
    "        snippetfilename = folder + '/' + shortfilename + 'snippet' + str(i+1) + '.wav'\n",
    "        #print snippetfilename\n",
    "        snippet = wave.open(snippetfilename ,'wb')\n",
    "        snippet.setnchannels(2)\n",
    "        snippet.setsampwidth(handle.getsampwidth())\n",
    "        snippet.setframerate(frame_rate)\n",
    "        #snippet.setsampwidth(2)\n",
    "        #snippet.setframerate(11025)\n",
    "        snippet.setnframes(handle.getnframes())\n",
    "        snippet.writeframes(handle.readframes(window_size))\n",
    "        handle.setpos(handle.tell() - 1 * frame_rate)\n",
    "        #print snippetfilename, \":\", snippet.getnchannels(), snippet.getframerate(), snippet.getnframes(), snippet.getsampwidth()\n",
    "        \n",
    "        #The last audio slice might be less than a second, if this is the case, we don't want to include it because it will not fit into our matrix \n",
    "        if last_number_frames < 1:\n",
    "            last_number_frames = snippet.getnframes()\n",
    "        elif snippet.getnframes() != last_number_frames:\n",
    "            #print \"this file doesnt have the same frame size!, remaming file\"\n",
    "            os.rename(snippetfilename, snippetfilename+\".bak\")\n",
    "        snippet.close()\n",
    "\n",
    "    #handle.close()\n",
    "\n",
    "\n",
    "chop_new_audio(\"babycryingformilk.wav\", \"babycryingformilk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Transform the chopped snippets into MFCC fingerprints and make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, filename in enumerate(os.listdir('babycryingformilk/')):\n",
    "    last_number_frames = -1\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"babycryingformilk/\"+filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        prediction = model.predict(fingerprint)\n",
    "        #print prediction\n",
    "        predictions.append(prediction[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Take the mode of the predictions to come up with a final predition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hungry', 29)]\n",
      "[('hungry', 29)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "data = Counter(predictions)\n",
    "print data.most_common()   # Returns all unique items and their counts\n",
    "print data.most_common(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So our algorithm worked! (But maybe we just got lucky)  I think when you build a bigger dataset and test with more sound files you will be able to see how well the algorithm really performs.  There are also many ways to adjust the algorithm parameters and test how that affects the accuracy of predictions.  I hope this is useful for getting started!  Let me know if you have any other questions or concerns and I will be more than happy to help!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
