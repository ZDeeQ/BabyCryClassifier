{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baby Cry Analysis & Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Grab the audio file and its label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Store all audio files in dictionary where key: filename, value: label\n",
    "import os\n",
    "raw_audio = dict()\n",
    "\n",
    "\n",
    "directory = 'Full_hunger'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'hungry'\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "directory = 'Full_pain'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'pain'\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "directory = 'Full_asphyxia'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".wav\"): \n",
    "        raw_audio[os.path.join(directory, filename)] = 'asphyxia'\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "#print raw_audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#If you are having issues with python being able to make the different directories, try doing it manually or with the os.system commands\n",
    "\n",
    "```os.system(\"sudo mkdir /audio\")```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2:  Chop the audio file into 1 sec. snippets and save them in separate folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('chopping: Full_pain/17.wav', 'pain')\n",
      "('chopping: Full_pain/24.wav', 'pain')\n",
      "('chopping: Full_hunger/39.wav', 'hungry')\n",
      "('chopping: Full_hunger/51.wav', 'hungry')\n",
      "('chopping: Full_pain/22.wav', 'pain')\n",
      "('chopping: Full_hunger/42.wav', 'hungry')\n",
      "('chopping: Full_pain/7.wav', 'pain')\n",
      "('chopping: Full_asphyxia/63.wav', 'asphyxia')\n",
      "('chopping: Full_pain/72.wav', 'pain')\n",
      "('chopping: Full_pain/10a.wav', 'pain')\n",
      "('chopping: Full_hunger/47.wav', 'hungry')\n",
      "('chopping: Full_pain/10.wav', 'pain')\n",
      "('chopping: Full_pain/73.wav', 'pain')\n",
      "('chopping: Full_hunger/37.wav', 'hungry')\n",
      "('chopping: Full_hunger/83.wav', 'hungry')\n",
      "('chopping: Full_hunger/4.wav', 'hungry')\n",
      "('chopping: Full_asphyxia/64.wav', 'asphyxia')\n",
      "('chopping: Full_asphyxia/67.wav', 'asphyxia')\n",
      "('chopping: Full_pain/13.wav', 'pain')\n",
      "('chopping: Full_hunger/80.wav', 'hungry')\n",
      "('chopping: Full_hunger/18.wav', 'hungry')\n",
      "('chopping: Full_hunger/88a.wav', 'hungry')\n",
      "('chopping: Full_hunger/36.wav', 'hungry')\n",
      "('chopping: Full_hunger/5.wav', 'hungry')\n",
      "('chopping: Full_hunger/43.wav', 'hungry')\n",
      "('chopping: Full_hunger/23.wav', 'hungry')\n",
      "('chopping: Full_pain/14.wav', 'pain')\n",
      "('chopping: Full_hunger/35.wav', 'hungry')\n",
      "('chopping: Full_hunger/75.wav', 'hungry')\n",
      "('chopping: Full_pain/50.wav', 'pain')\n",
      "('chopping: Full_pain/20.wav', 'pain')\n",
      "('chopping: Full_hunger/44.wav', 'hungry')\n",
      "('chopping: Full_pain/6.wav', 'pain')\n",
      "('chopping: Full_pain/19.wav', 'pain')\n",
      "('chopping: Full_hunger/48.wav', 'hungry')\n",
      "('chopping: Full_pain/2.wav', 'pain')\n",
      "('chopping: Full_hunger/34.wav', 'hungry')\n",
      "('chopping: Full_hunger/33.wav', 'hungry')\n",
      "('chopping: Full_asphyxia/66.wav', 'asphyxia')\n",
      "('chopping: Full_pain/3.wav', 'pain')\n",
      "('chopping: Full_hunger/77.wav', 'hungry')\n",
      "('chopping: Full_pain/9b.wav', 'pain')\n",
      "('chopping: Full_pain/15.wav', 'pain')\n",
      "('chopping: Full_pain/74.wav', 'pain')\n",
      "('chopping: Full_pain/1.wav', 'pain')\n",
      "('chopping: Full_pain/49.wav', 'pain')\n",
      "('chopping: Full_hunger/41.wav', 'hungry')\n",
      "('chopping: Full_hunger/16.wav', 'hungry')\n",
      "('chopping: Full_hunger/11.wav', 'hungry')\n",
      "('chopping: Full_hunger/46.wav', 'hungry')\n",
      "('chopping: Full_hunger/38.wav', 'hungry')\n",
      "('chopping: Full_hunger/79.wav', 'hungry')\n",
      "('chopping: Full_asphyxia/68.wav', 'asphyxia')\n",
      "('chopping: Full_hunger/21.wav', 'hungry')\n",
      "('chopping: Full_hunger/12.wav', 'hungry')\n",
      "('chopping: Full_pain/45.wav', 'pain')\n",
      "('chopping: Full_hunger/76.wav', 'hungry')\n",
      "('chopping: Full_hunger/81.wav', 'hungry')\n",
      "('chopping: Full_hunger/40.wav', 'hungry')\n",
      "('chopping: Full_pain/32.wav', 'pain')\n",
      "('chopping: Full_pain/8.wav', 'pain')\n",
      "('chopping: Full_pain/9a.wav', 'pain')\n",
      "('chopping: Full_asphyxia/65.wav', 'asphyxia')\n"
     ]
    }
   ],
   "source": [
    "import wave \n",
    "import math\n",
    "\n",
    "def chop_song(filename, folder):\n",
    "    handle = wave.open(filename, 'rb')\n",
    "    frame_rate = handle.getframerate()\n",
    "    n_frames = handle.getnframes()\n",
    "    window_size = 2 * frame_rate\n",
    "    num_secs = int(math.ceil(n_frames/frame_rate))\n",
    "\n",
    "\n",
    "    #Slicing Audio file\n",
    "    for i in xrange(num_secs):\n",
    "        filename = 'audio/' + folder + '/snippet'+ str(i+1) + '.wav'\n",
    "        snippet = wave.open(filename ,'wb')\n",
    "        snippet.setnchannels(2)\n",
    "        snippet.setsampwidth(handle.getsampwidth())\n",
    "        snippet.setframerate(frame_rate)\n",
    "        snippet.writeframes(handle.readframes(window_size))\n",
    "        handle.setpos(handle.tell() - 1 * frame_rate)\n",
    "        snippet.close()\n",
    "\n",
    "    handle.close()\n",
    "\n",
    "for audio_file in raw_audio:\n",
    "    chop_song(audio_file, raw_audio[audio_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3:  Transform .wav to frequency spectrum\n",
    "Some files had some sample rate issues and caused errors in this step. If this happens, print out the file name at each pass and if one of the files is causing an error, go ahead and delete it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa \n",
    "import numpy as np\n",
    "'''Chop and Transform each track'''\n",
    "X = pd.DataFrame(columns = np.arange(45), dtype = 'float32').astype(np.float32)\n",
    "j = 0\n",
    "k = 0\n",
    "for i, filename in enumerate(os.listdir('audio/pain/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audiofile, sr = librosa.load(\"audio/pain/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'pain'\n",
    "        X.loc[i] = x.loc[0]\n",
    "        j = i \n",
    "        \n",
    "\n",
    "for i, filename in enumerate(os.listdir('audio/hungry/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        audiofile, sr = librosa.load(\"audio/hungry/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'hungry'\n",
    "        X.loc[i+j] = x.loc[0] \n",
    "        k = i \n",
    "        \n",
    "for i, filename in enumerate(os.listdir('audio/asphyxia/')):\n",
    "    if filename.endswith(\".wav\"):\n",
    "        #print filename\n",
    "        audiofile, sr = librosa.load(\"audio/asphyxia/\" + filename)\n",
    "        fingerprint = librosa.feature.mfcc(y=audiofile, sr=sr, n_mfcc=1)\n",
    "        x = pd.DataFrame(fingerprint, dtype = 'float32')\n",
    "        x[44] = 'asphyxia'\n",
    "        X.loc[i+j+k] = x.loc[0]\n",
    "        \n",
    "#Do something with missing values\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4:  Make a Test-Train-Split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "y = X[44]\n",
    "del X[44]\n",
    "X = X.astype(np.float32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5:  Fit the training data to a model & Check the models performance against the test dataÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Model, Accuracy, Precision, Recall\n",
      "    Random Forest: (0.967741935483871, 0.97235023041474655, 0.967741935483871)\n",
      "    Logistic Regression: (0.83870967741935487, 0.83136200716845876, 0.83870967741935487)\n",
      "    Decision Tree: (1.0, 1.0, 1.0)\n",
      "    SVM: (0.5161290322580645, 0.26638917793964617, 0.5161290322580645)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "\n",
    "def get_scores(classifier, X_train, X_test, y_train, y_test, **kwargs):\n",
    "        model = classifier(**kwargs)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_predict = model.predict(X_test)\n",
    "        return model.score(X_test, y_test), \\\n",
    "               precision_score(y_test, y_predict), \\\n",
    "               recall_score(y_test, y_predict)\n",
    "\n",
    "print \"    Model, Accuracy, Precision, Recall\"\n",
    "print \"    Random Forest:\", get_scores(RandomForestClassifier, X_train, X_test, y_train, y_test, n_estimators=25, max_features=5)\n",
    "print \"    Logistic Regression:\", get_scores(LogisticRegression, X_train, X_test, y_train, y_test)\n",
    "print \"    Decision Tree:\", get_scores(DecisionTreeClassifier, X_train, X_test, y_train, y_test)\n",
    "print \"    SVM:\", get_scores(SVC, X_train, X_test, y_train, y_test)\n",
    "#print \"    Naive Bayes:\", get_scores(MultinomialNB, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Model: (Accuracy, Precision, Recall)\n",
    "    Random Forest: (0.967741935483871, 0.97235023041474655, 0.967741935483871)\n",
    "    Logistic Regression: (0.83870967741935487, 0.83136200716845876, 0.83870967741935487)\n",
    "    Decision Tree: (1.0, 1.0, 1.0)\n",
    "    SVM: (0.5161290322580645, 0.26638917793964617, 0.5161290322580645)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you are satisfied with the results of your model, you can save the model into a .pkl file that you can quickly use to make predictions of new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pickle_model(model, modelname):\n",
    "    with open('../models/' + str(modelname) + '.pkl', 'wb') as f:\n",
    "        return cPickle.dump(model, f)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After you pkl a model you can open it up later on as so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getModel(pickle_path):\n",
    "    with open(pickle_path, 'rb') as f:\n",
    "        return cPickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Actual Predictions on new sounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can decide how you want to set up your system to receive and process the audio files it receives. I chose to use concurrent queues in order to make multiple predictions and take the most common result of multiple 1-second slices of audio input.  You may choose to do something else, but as of right now, your algorithm makes a prediction based upon just one second of sound.  Here is some code that I used to make predictions after the audio was already chopped, MFCC transformed into an audio \"fingerprint\" , and placed in a queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(fingerprint_queue,prediction_queue, model):\n",
    "    while True:\n",
    "        if not fingerprint_queue.empty():\n",
    "            print \"Predictor Worker waking up...\\n\"\n",
    "            fingerprint = fingerprint_queue.get()\n",
    "\n",
    "            X = fingerprint[0].reshape(1, -1)\n",
    "            prediction = model.predict(X)\n",
    "            print \"PREDICTION: \", prediction\n",
    "            prediction_queue.put([prediction, fingerprint[1]])\n",
    "\n",
    "        else:\n",
    "            #print \"Predictor worker waiting....\\n\"\n",
    "            sleep(.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope this is useful!  Let me know if you have any other questions or concerns and I will be more than happy to help!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
